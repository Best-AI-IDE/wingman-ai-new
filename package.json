{
	"name": "wing-man",
	"displayName": "Wingman-AI",
	"description": "Wingman - AI powered assistant to help you write your best code, we won't leave you hanging.",
	"version": "0.7.0",
	"publisher": "WingMan",
	"license": "MIT",
	"workspaces": [
		"webview-ui",
		"configview-ui",
		"views-ui",
		"shared"
	],
	"authors": [
		[
			{
				"name": "Russell Canfield",
				"email": "rcanfield86@gmail.com"
			},
			{
				"name": "Harlen Alvarez",
				"email": "harlenalvarez@gmail.com"
			}
		]
	],
	"icon": "media/icon.png",
	"galleryBanner": {
		"color": "#262626",
		"theme": "dark"
	},
	"contributors": [
		{
			"name": "Russell Canfield",
			"email": "rcanfield86@gmail.com"
		},
		{
			"name": "Harlen Alvarez",
			"email": "harlenalvarez@gmail.com"
		}
	],
	"repository": {
		"type": "git",
		"url": "https://github.com/RussellCanfield/wingman-ai"
	},
	"engines": {
		"vscode": "^1.87.0"
	},
	"categories": [
		"Programming Languages",
		"Snippets",
		"Machine Learning",
		"Education"
	],
	"pricing": "Free",
	"keywords": [
		"ai",
		"codestral",
		"chatgpt",
		"copilot",
		"intellisense",
		"openai",
		"anthropic",
		"composer",
		"gpt",
		"chat",
		"ollama",
		"huggingface",
		"code assistant"
	],
	"activationEvents": [
		"onStartupFinished",
		"onLanguage:plaintext"
	],
	"main": "./out/extension.js",
	"contributes": {
		"icons": {
			"wingman-logo": {
				"description": "Wingman icon",
				"default": {
					"fontPath": "media/wingman.woff",
					"fontCharacter": "\\e900"
				}
			}
		},
		"languages": [
			{
				"id": "plaintext",
				"aliases": [
					"Plain Text",
					"plaintext"
				],
				"extensions": [
					".txt",
					".text"
				]
			}
		],
		"viewsContainers": {
			"activitybar": [
				{
					"id": "wing-man",
					"title": "Wingman",
					"icon": "media/wingman-logo.png"
				}
			],
			"panel": [
				{
					"id": "wing-man-config",
					"title": "Wingman Config",
					"icon": "media/wingman-logo.png"
				}
			]
		},
		"views": {
			"wing-man": [
				{
					"id": "wing-man-chat-view",
					"name": "We've got your back!",
					"type": "webview"
				}
			],
			"wing-man-config": [
				{
					"id": "wingman.configview",
					"name": "Wingman Config",
					"type": "webview"
				}
			]
		},
		"configuration": {
			"title": "Wingman",
			"properties": {
				"Wingman.Provider": {
					"type": "string",
					"default": "Ollama",
					"enum": [
						"Ollama",
						"HuggingFace",
						"OpenAI",
						"Anthropic"
					],
					"description": "Specifies which AI provider to use - some require configuration."
				},
				"Wingman.InteractionSettings": {
					"type": "object",
					"description": "Interaction settings help configure how parts of the extension interact with the LLM(s).",
					"default": {
						"codeCompletionEnabled": true,
						"codeStreaming": false,
						"codeContextWindow": 256,
						"codeMaxTokens": -1,
						"chatContextWindow": 4096,
						"chatMaxTokens": 4096
					},
					"properties": {
						"codeCompletionEnabled": {
							"type": "boolean",
							"default": true,
							"description": "Turns on automated code completion. Code completion will run when you type in a file for a supported language."
						},
						"codeStreaming": {
							"type": "boolean",
							"default": false,
							"description": "Turns on streaming for code complete in order for code completion to return faster results at the expense of shorter answers"
						},
						"codeContextWindow": {
							"type": "number",
							"default": 256,
							"description": "The default context window size for code completion. Larger is higher quality with less performance."
						},
						"codeMaxTokens": {
							"type": "number",
							"default": -1,
							"description": "The amount of tokens allowed in the LLM response for code completion (num_predict in Ollama), -1 is infinite."
						},
						"chatContextWindow": {
							"type": "number",
							"default": 4096,
							"description": "The default context window size for chat. Can be increased for running larger models."
						},
						"chatMaxTokens": {
							"type": "number",
							"default": 4096,
							"description": "The amount of tokens allowed in the LLM response for chat (num_predict in Ollama), -1 is infinite."
						}
					}
				},
				"Wingman.EmbeddingProvider": {
					"type": "string",
					"default": "Ollama",
					"enum": [
						"Ollama",
						"OpenAI"
					],
					"description": "Specifies which AI provider to use - some require configuration."
				},
				"Wingman.OllamaEmbeddingSettings": {
					"type": "object",
					"description": "Embedding settings configure how the extension interacts with the embedding service.",
					"default": {
						"embeddingModel": "mxbai-embed-large",
						"baseUrl": "http://localhost:11434"
					},
					"properties": {
						"embeddingModel": {
							"type": "string",
							"default": "mxbai-embed-large",
							"description": "The model to use for embeddings"
						},
						"dimensions": {
							"type": "number",
							"default": 1024,
							"description": "The number of dimensions for the embeddings"
						},
						"baseUrl": {
							"type": "string",
							"default": "http://localhost:11434",
							"description": "Base URL for the ollama instance"
						}
					}
				},
				"Wingman.OpenAIEmbeddingSettings": {
					"type": "object",
					"description": "Embedding settings configure how the extension interacts with the embedding service.",
					"default": {
						"embeddingModel": "text-embedding-ada-002",
						"apiKey": "ADD ME"
					},
					"properties": {
						"embeddingModel": {
							"type": "string",
							"default": "text-embedding-ada-002",
							"description": "The model to use for embeddings"
						},
						"apiKey": {
							"type": "string",
							"default": "ADD ME",
							"description": "The API key to use for OpenAI"
						},
						"dimensions": {
							"type": "number",
							"default": 1536,
							"description": "The number of dimensions for the embeddings"
						}
					}
				},
				"Wingman.Ollama": {
					"type": "object",
					"description": "Ollama settings",
					"default": {
						"chatModel": "deepseek-coder:6.7b-instruct-q8_0",
						"codeModel": "deepseek-coder:6.7b-base-q8_0",
						"baseUrl": "http://localhost:11434",
						"apiPath": "/api/generate",
						"modelInfoPath": "/api/show"
					},
					"properties": {
						"chatModel": {
							"type": "string",
							"default": "deepseek-coder:6.7b-instruct-q8_0",
							"description": "The model to use for the chat"
						},
						"codeModel": {
							"type": "string",
							"default": "deepseek-coder:6.7b-base-q8_0",
							"description": "The model to use for the code completion"
						},
						"baseUrl": {
							"type": "string",
							"default": "http://localhost:11434",
							"description": "Base URL for the ollama instance"
						},
						"apiPath": {
							"type": "string",
							"default": "/api/generate",
							"description": "Path for generation"
						},
						"modelInfoPath": {
							"type": "string",
							"default": "/api/show",
							"description": "Path for model info"
						}
					}
				},
				"Wingman.HuggingFace": {
					"type": "object",
					"description": "HuggingFace settings",
					"default": {
						"chatModel": "mistralai/Mixtral-8x7B-Instruct-v0.1",
						"codeModel": "codellama/CodeLlama-7b-hf",
						"baseUrl": "https://api-inference.huggingface.co/models/",
						"apiKey": "ADD ME"
					},
					"properties": {
						"chatModel": {
							"type": "string",
							"default": "mistralai/Mixtral-8x7B-Instruct-v0.1",
							"description": "The model to use for the chat"
						},
						"codeModel": {
							"type": "string",
							"default": "codellama/CodeLlama-7b-hf",
							"description": "The model to use for the code completion"
						},
						"baseUrl": {
							"type": "string",
							"default": "https://api-inference.huggingface.co/models/",
							"description": "Base URL for the HuggingFace inference endpoint"
						},
						"apiKey": {
							"type": "string",
							"default": "ADD ME",
							"description": "The API key to use for HuggingFace"
						}
					}
				},
				"Wingman.OpenAI": {
					"type": "object",
					"description": "OpenAI settings",
					"default": {
						"chatModel": "gpt-4o-2024-08-06",
						"codeModel": "gpt-4o-2024-08-06",
						"baseUrl": "https://api.openai.com/v1/chat/completions",
						"apiKey": "ADD ME"
					},
					"properties": {
						"chatModel": {
							"type": "string",
							"default": "gpt-4o-2024-08-06",
							"description": "The model to use for the chat"
						},
						"codeModel": {
							"type": "string",
							"default": "gpt-4o-2024-08-06",
							"description": "The model to use for the code completion"
						},
						"baseUrl": {
							"type": "string",
							"default": "https://api.openai.com/v1/chat/completions",
							"description": "Base URL for the OpenAI API"
						},
						"apiKey": {
							"type": "string",
							"default": "ADD ME",
							"description": "The API key to use for OpenAI"
						}
					}
				},
				"Wingman.Anthropic": {
					"type": "object",
					"description": "Anthropic settings",
					"default": {
						"chatModel": "claude-3-5-sonnet-20240620",
						"codeModel": "claude-3-5-sonnet-20240620",
						"baseUrl": "https://api.anthropic.com/v1",
						"apiKey": "ADD ME"
					},
					"properties": {
						"chatModel": {
							"type": "string",
							"default": "claude-3-5-sonnet-20240620",
							"description": "The model to use for the chat"
						},
						"codeModel": {
							"type": "string",
							"default": "claude-3-5-sonnet-20240620",
							"description": "The model to use for the code completion"
						},
						"baseUrl": {
							"type": "string",
							"default": "https://api.anthropic.com/v1",
							"description": "Base URL for the Anthropic API"
						},
						"apiKey": {
							"type": "string",
							"default": "ADD ME",
							"description": "The API key to use for Anthropic"
						}
					}
				}
			}
		},
		"commands": [
			{
				"command": "wingmanai.gendocument",
				"title": "Gen Docs"
			},
			{
				"command": "wingmanai.refactorcode",
				"title": "Refactor Code"
			},
			{
				"command": "wingmanai.triggercodecomplete",
				"title": "Code Complete"
			}
		],
		"keybindings": [
			{
				"command": "wingmanai.triggercodecomplete",
				"key": "ctrl+shift+space"
			}
		]
	},
	"scripts": {
		"install:all": "npm install && cd webview-ui && npm install",
		"start:views": "cd webview-ui && npm run start",
		"build": "tsc -b",
		"build:views": "cd views-ui && npm run build",
		"build:shared": "cd shared && npm run build",
		"vscode:prepublish": "npm run compile",
		"compile": "npm run clean && npm run build:shared && npm run build:views && tsc -b",
		"watch": "tsc -b --watch",
		"watch:views": "npm run build && cd views-ui && npm run dev",
		"pretest": "npm run compile && npm run lint",
		"lint": "eslint src --ext ts",
		"clean": "rimraf out"
	},
	"dependencies": {
		"@langchain/langgraph": "0.2.2",
		"@langchain/community": "0.2.33",
		"@langchain/openai": "0.2.10",
		"@langchain/anthropic": "0.2.18",
		"@langchain/ollama": "0.0.4",
		"vscode-languageclient": "9.0.1",
		"vscode-languageserver": "9.0.1",
		"vscode-languageserver-textdocument": "1.0.12",
		"vscode-uri": "3.0.8",
		"@ast-grep/napi": "0.27.1",
		"langchain": "0.2.18",
		"vectra": "0.9.0",
		"zod-to-json-schema": "3.23.3"
	},
	"devDependencies": {
		"@types/mocha": "10.0.6",
		"@types/node": "22.5.4",
		"@types/vscode": "1.93.0",
		"@types/vscode-webview": "1.57.5",
		"@vscode/codicons": "0.0.36",
		"@vscode/test-cli": "0.0.10",
		"@vscode/test-electron": "2.4.1",
		"generate-license-file": "3.5.1",
		"@vscode/webview-ui-toolkit": "1.4.0",
		"rimraf": "^6.0.1",
		"ts-node": "10.9.2",
		"tsconfig-paths": "4.2.0",
		"typescript": "^5.6.2"
	}
}
